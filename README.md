# Deal Win Probability Prediction Tool

[![Python](https://img.shields.io/badge/Python-3.10%2B-blue)](https://www.python.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104%2B-green)](https://fastapi.tiangolo.com/)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.28%2B-red)](https://streamlit.io/)
[![XGBoost](https://img.shields.io/badge/XGBoost-2.0%2B-orange)](https://xgboost.readthedocs.io/)

A comprehensive machine learning solution for predicting deal win probability using XGBoost classifier. The tool provides both a REST API (FastAPI) and an interactive web UI (Streamlit) for generating synthetic training data, training models, and making predictions.

## ğŸ“‹ Table of Contents

- [Features](#features)
- [Project Structure](#project-structure)
- [Installation](#installation)
- [Quick Start](#quick-start)
- [Usage](#usage)
  - [Backend API](#backend-api)
  - [Frontend UI](#frontend-ui)
  - [Command Line](#command-line)
- [API Documentation](#api-documentation)
- [Development](#development)
- [Deployment](#deployment)
- [Contributing](#contributing)
- [License](#license)

## âœ¨ Features

### Core Functionality
- **Synthetic Data Generation**: Create realistic training data with configurable parameters
- **Model Training**: Train XGBoost classifier with automatic validation
- **Prediction**: Upload Excel files and get instant deal outcome predictions
- **Dual Interface**: Choose between REST API or interactive web UI

### Backend (FastAPI)
- RESTful API endpoints
- Automatic OpenAPI/Swagger documentation
- File upload and download support
- Comprehensive error handling
- Postman collection included

### Frontend (Streamlit)
- Modern, responsive web interface
- Real-time progress tracking
- Interactive data visualization
- Drag-and-drop file upload
- Downloadable results

### Machine Learning
- XGBoost classifier for high accuracy
- Automatic feature engineering
- Label encoding for categorical variables
- Model persistence with joblib
- Validation metrics

## ğŸ“ Project Structure

```
POC - Probability Tool/
â”‚
â”œâ”€â”€ backend/                      # Backend services
â”‚   â”œâ”€â”€ api/                      # FastAPI application
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ main.py              # FastAPI app entry point
â”‚   â”‚   â”œâ”€â”€ routes/              # API route handlers
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ data.py         # Data generation endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ model.py        # Model training endpoints
â”‚   â”‚   â”‚   â””â”€â”€ predict.py      # Prediction endpoints
â”‚   â”‚   â””â”€â”€ schemas/            # Pydantic models
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â””â”€â”€ models.py       # Request/response schemas
â”‚   â”‚
â”‚   â”œâ”€â”€ core/                    # Core business logic
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ data_generator.py  # Synthetic data generation
â”‚   â”‚   â”œâ”€â”€ model_trainer.py   # Model training logic
â”‚   â”‚   â””â”€â”€ predictor.py       # Prediction logic
â”‚   â”‚
â”‚   â””â”€â”€ utils/                   # Backend utilities
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ helpers.py          # Helper functions
â”‚
â”œâ”€â”€ frontend/                    # Frontend application
â”‚   â”œâ”€â”€ streamlit_app.py        # Streamlit app entry point
â”‚   â”œâ”€â”€ pages/                  # Streamlit pages
â”‚   â”‚   â”œâ”€â”€ 1_ğŸ“_Data_Generation.py
â”‚   â”‚   â”œâ”€â”€ 2_ğŸ¤–_Model_Training.py
â”‚   â”‚   â”œâ”€â”€ 3_ğŸ”®_Predictions.py
â”‚   â”‚   â””â”€â”€ 4_â„¹ï¸_About.py
â”‚   â””â”€â”€ components/             # Reusable UI components
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ sidebar.py
â”‚       â””â”€â”€ metrics.py
â”‚
â”œâ”€â”€ data/                        # Data storage
â”‚   â”œâ”€â”€ input/                  # Input data files
â”‚   â”œâ”€â”€ output/                 # Generated outputs
â”‚   â””â”€â”€ cache/                  # Temporary cache
â”‚
â”œâ”€â”€ models/                      # Trained models
â”‚   â””â”€â”€ xgb_classifier.pkl      # Saved XGBoost model
â”‚
â”œâ”€â”€ config/                      # Configuration files
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ settings.py             # Application settings
â”‚
â”œâ”€â”€ docs/                        # Documentation
â”‚   â”œâ”€â”€ API_SETUP.md
â”‚   â”œâ”€â”€ FASTAPI_GUIDE.md
â”‚   â”œâ”€â”€ STREAMLIT_GUIDE.md
â”‚   â””â”€â”€ PROJECT_STRUCTURE.md
â”‚
â”œâ”€â”€ tests/                       # Test suite
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_api.py
â”‚   â”œâ”€â”€ test_data_generator.py
â”‚   â””â”€â”€ test_predictor.py
â”‚
â”œâ”€â”€ scripts/                     # Utility scripts
â”‚   â”œâ”€â”€ setup.py                # Setup script
â”‚   â””â”€â”€ verify_structure.py     # Structure verification
â”‚
â”œâ”€â”€ .gitignore                   # Git ignore file
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ requirements-dev.txt         # Development dependencies
â”œâ”€â”€ README.md                    # This file
â”œâ”€â”€ LICENSE                      # License file
â””â”€â”€ Dockerfile                   # Docker configuration

```

## ğŸš€ Installation

### Prerequisites
- Python 3.10 or higher
- pip (Python package manager)
- Virtual environment (recommended)

### Step 1: Clone the Repository
```bash
git clone <repository-url>
cd "POC - Probability Tool"
```

### Step 2: Create Virtual Environment
```bash
# Windows
python -m venv venv
venv\Scripts\activate

# Linux/Mac
python3 -m venv venv
source venv/bin/activate
```

### Step 3: Install Dependencies
```bash
# Install production dependencies
pip install -r requirements.txt

# Install development dependencies (optional)
pip install -r requirements-dev.txt
```

## ğŸ¯ Quick Start

### Option 1: Run Backend API
```bash
# Start FastAPI server
python -m backend.api.main

# Or using uvicorn directly
uvicorn backend.api.main:app --reload --host 0.0.0.0 --port 8000
```

Access the API at:
- **Swagger UI**: http://localhost:8000/swagger
- **ReDoc**: http://localhost:8000/redoc
- **API Base**: http://localhost:8000

### Option 2: Run Frontend UI
```bash
# Start Streamlit app
streamlit run frontend/streamlit_app.py

# Or using python module
python -m streamlit run frontend/streamlit_app.py
```

Access the UI at: http://localhost:8501

### Option 3: Run Both Simultaneously
```bash
# Terminal 1: Start Backend
python -m backend.api.main

# Terminal 2: Start Frontend
streamlit run frontend/streamlit_app.py
```

## ğŸ“– Usage

### Backend API

#### 1. Generate Synthetic Data
```bash
curl -X POST "http://localhost:8000/generate-synthetic-data"
```

#### 2. Train Model
```bash
curl -X POST "http://localhost:8000/train-model"
```

#### 3. Make Predictions
```bash
curl -X POST "http://localhost:8000/predict" \
  -F "file=@data/input/Data-Input.xlsx"
```

#### 4. Download Predictions
```bash
curl -X GET "http://localhost:8000/download-predictions/{filename}" \
  --output predictions.xlsx
```

### Frontend UI

1. **Navigate to Home**: View dashboard and system status
2. **Generate Data**: Create synthetic training data
3. **Train Model**: Train the XGBoost classifier
4. **Make Predictions**: Upload Excel file and get predictions
5. **Download Results**: Save predictions as Excel file

### Command Line

Run the complete pipeline:
```bash
python main.py
```

Individual scripts:
```bash
# Generate synthetic data
python backend/core/data_generator.py

# Train model
python backend/core/model_trainer.py

# Make predictions
python backend/core/predictor.py
```

## ğŸ“š API Documentation

### Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| GET | `/` | API information |
| GET | `/health` | Health check |
| POST | `/generate-synthetic-data` | Generate training data |
| POST | `/train-model` | Train XGBoost model |
| POST | `/predict` | Upload file and predict |
| GET | `/download-predictions/{filename}` | Download predictions |
| GET | `/model-info` | Get model information |

### Request/Response Examples

See [FASTAPI_GUIDE.md](docs/FASTAPI_GUIDE.md) for detailed API documentation.

### Postman Collection

Import `Deal_Win_Probability_API.postman_collection.json` into Postman for pre-configured API requests.

## ğŸ› ï¸ Development

### Running Tests
```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=backend --cov=frontend

# Run specific test file
pytest tests/test_api.py
```

### Code Quality
```bash
# Format code
black backend/ frontend/

# Lint code
flake8 backend/ frontend/

# Type checking
mypy backend/ frontend/
```

### Project Verification
```bash
# Verify project structure
python scripts/verify_structure.py
```

## ğŸ³ Deployment

### Docker

Build and run with Docker:
```bash
# Build image
docker build -t deal-win-api .

# Run container
docker run -p 8000:8000 -p 8501:8501 deal-win-api
```

### Docker Compose

```bash
# Start all services
docker-compose up -d

# Stop services
docker-compose down
```

### Production Deployment

#### FastAPI with Gunicorn
```bash
gunicorn backend.api.main:app \
  -w 4 \
  -k uvicorn.workers.UvicornWorker \
  --bind 0.0.0.0:8000
```

#### Streamlit Cloud
1. Push to GitHub
2. Connect to Streamlit Cloud
3. Deploy with one click

## ğŸ”§ Configuration

Edit `config/settings.py` to customize:
- Model parameters
- File paths
- API settings
- UI configuration

## ğŸ“Š Data Format

### Input Excel File Structure
```
| CRM ID | Account Name | Opportunity Name | Expected TCV | ... |
|--------|--------------|------------------|--------------|-----|
| CRM001 | HSBC         | Deal 1          | 50.5         | ... |
```

### Output Excel File Structure
```
| CRM ID | Account Name | ... | Predicted Deal Status |
|--------|--------------|-----|----------------------|
| CRM001 | HSBC         | ... | Won                  |
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ‘¥ Authors

- **Your Name** - *Initial work*

## ğŸ™ Acknowledgments

- XGBoost team for the excellent ML library
- FastAPI team for the modern web framework
- Streamlit team for the interactive UI framework
- Scikit-learn for preprocessing utilities

## ğŸ“ Support

For support, email your-email@example.com or open an issue in the repository.

## ğŸ—ºï¸ Roadmap

- [ ] Add authentication and authorization
- [ ] Implement model versioning
- [ ] Add more ML algorithms (Random Forest, Neural Networks)
- [ ] Create mobile-responsive UI
- [ ] Add real-time prediction monitoring
- [ ] Implement A/B testing for models
- [ ] Add data validation and cleaning
- [ ] Create automated retraining pipeline

## ğŸ“ˆ Performance

- **Training Time**: ~10-30 seconds for 30 records
- **Prediction Time**: <1 second for 100 records
- **Model Size**: ~2-5 MB
- **API Response Time**: <100ms average

## ğŸ”’ Security

- Input validation on all endpoints
- File type verification
- Size limits on uploads
- CORS configuration
- Rate limiting (production)

## ğŸŒŸ Star History

If you find this project useful, please consider giving it a star!

---

**Built with â¤ï¸ using Python, FastAPI, Streamlit, and XGBoost**
